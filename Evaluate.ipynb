{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bag',\n",
       " 'Book',\n",
       " 'Chair',\n",
       " 'Cup',\n",
       " 'Eraser',\n",
       " 'Fork',\n",
       " 'Pen',\n",
       " 'Pencil',\n",
       " 'Pencil Case',\n",
       " 'Plate',\n",
       " 'Soap',\n",
       " 'Spoon',\n",
       " 'Table',\n",
       " 'Toothbrush',\n",
       " 'Toothpaste']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasetDir = 'Dataset'\n",
    "\n",
    "# get the Subdirectory of the Dataset Folder\n",
    "for root, folder, files in os.walk(datasetDir):\n",
    "    if folder != []:\n",
    "        listDir = folder\n",
    "\n",
    "classes = []\n",
    "# retrieve the name and the number of the classification\n",
    "for i, category in enumerate(listDir):\n",
    "    # print(category)\n",
    "    classes.append(category)\n",
    "    # classes.append({'name' : category,'id' : i + 1, \"category\" : category})\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2615 images belonging to 15 classes.\n",
      "Found 2615 images belonging to 15 classes.\n",
      "Found 647 images belonging to 15 classes.\n",
      "Found 647 images belonging to 15 classes.\n",
      "Found 291 images belonging to 15 classes.\n",
      "Found 291 images belonging to 15 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Create a datagen that is split the dataset into 80% Train and 20% Test\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=90,\n",
    "    # shear_range=0.2,\n",
    "    zoom_range=0.5,\n",
    "    width_shift_range=0.5,\n",
    "    height_shift_range=0.5,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2,\n",
    ")\n",
    "\n",
    "\n",
    "test_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    ")\n",
    "\n",
    "# Training Set\n",
    "training_set = datagen.flow_from_directory(\n",
    "    datasetDir,\n",
    "    target_size=(299,299),\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    shuffle=True,\n",
    "    subset=\"training\",\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "training_set_2 = datagen.flow_from_directory(\n",
    "    datasetDir,\n",
    "    target_size=(224,224),\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    shuffle=True,\n",
    "    subset=\"training\",\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Validation Set\n",
    "validation_set = datagen.flow_from_directory(\n",
    "    datasetDir,\n",
    "    target_size=(299,299),\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    shuffle=True,\n",
    "    subset=\"validation\",\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "validation_set_2 = datagen.flow_from_directory(\n",
    "    datasetDir,\n",
    "    target_size=(224,224),\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    shuffle=True,\n",
    "    subset=\"validation\",\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "test_set = test_datagen.flow_from_directory(\n",
    "    'Test Set',\n",
    "    target_size=(299,299),\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    shuffle=True,\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "test_set_2 = test_datagen.flow_from_directory(\n",
    "    'Test Set',\n",
    "    target_size=(224,224),\n",
    "    class_mode='categorical',\n",
    "    color_mode='rgb',\n",
    "    shuffle=True,\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image_path = 'Dataset/Soap/Soap_4.jpg'\n",
    "# augment = 'vertical_flip'\n",
    "\n",
    "# img = tf.keras.preprocessing.image.load_img(image_path, target_size= (224,224))\n",
    "# img_tensor = tf.keras.preprocessing.image.img_to_array(img)\n",
    "# img_tensor = np.expand_dims(img_tensor, axis=0)\n",
    "\n",
    "# #Uses ImageDataGenerator to flip the images\n",
    "# show_datagen = ImageDataGenerator(\n",
    "#     # rescale=1./255,\n",
    "#     # rotation_range=90,\n",
    "#     # shear_range=20,\n",
    "#     # zoom_range=0.5,\n",
    "#     # width_shift_range=[-0.2, 0.2],\n",
    "#     # height_shift_range=[-0.2, 0.2],\n",
    "#     # horizontal_flip=True,\n",
    "#     vertical_flip=True,\n",
    "#     # validation_split=0.2,\n",
    "# )\n",
    "\n",
    "# #Creates our batch of one image\n",
    "# pic = show_datagen.flow(img_tensor, batch_size =1)\n",
    "# fig = plt.figure(figsize=(10,8))\n",
    "# img_flat = np.squeeze(img_tensor)\n",
    "# ax1 = fig.add_subplot(1,5,1)\n",
    "# ax1.title.set_text('Original')\n",
    "# plt.imshow((img_flat).astype(np.uint8))\n",
    "# plt.axis('off')\n",
    "\n",
    "# #Plots our figures\n",
    "# for i in range(2,5):\n",
    "#   fig.add_subplot(1, 5, i)\n",
    "#   batch = pic.next()\n",
    "#   image_ = batch[0].astype('uint8')\n",
    "#   plt.imshow(image_)\n",
    "#   plt.axis('off')\n",
    "#   plt.savefig(f\"Augment/{augment}.png\", bbox_inches='tight')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 6s 382ms/step - loss: 0.6529 - accuracy: 0.8282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.6529161930084229, 'accuracy': 0.8281787037849426}"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "InceptionV3 = tf.keras.models.load_model('Model/InceptionV3/InceptionV3-Adam-0.0001-256Batch.h5')\n",
    "InceptionV3.evaluate(test_set, verbose=1,  return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 5s 421ms/step - loss: 1.5738 - accuracy: 0.6598\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 1.573818564414978, 'accuracy': 0.6597937941551208}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Vgg_19 = tf.keras.models.load_model('Model/VGG-19/VGG-19-Adam-0.0001-256Batch.h5')\n",
    "Vgg_19.evaluate(test_set_2 , verbose=1,  return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 4s 277ms/step - loss: 1.6557 - accuracy: 0.7285\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 1.6556593179702759, 'accuracy': 0.7285223603248596}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MobileNet = tf.keras.models.load_model('Model/MobileNet/MobileNet-Nadam-0.0001-256Batch.h5')\n",
    "MobileNet.evaluate(test_set_2, verbose=1,return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in Vgg_19.layers:\n",
    "    layer._name = layer.name + str('_2')\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in MobileNet.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "for layer in InceptionV3.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged =  tf.keras.layers.Concatenate(axis=1)([MobileNet.layers[-1].output, Vgg_19.layers[-1].output])\n",
    "# classify = tf.keras.layers.Dense(len(classes) , activation='softmax')(merged)\n",
    "# model = tf.keras.Model(inputs=[(MobileNet.input, Vgg_19.input)] , outputs=classify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(\n",
    "#     optimizer=tf.keras.optimizers.SGD(learning_rate=0.01),\n",
    "#     loss=tf.keras.losses.CategoricalCrossentropy(),\n",
    "#     metrics= ['accuracy']\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(\n",
    "#     [training_set_2 , training_set_2], \n",
    "#     epochs= 10,\n",
    "#     verbose = 1,\n",
    "#     validation_data = [validation_set_2, validation_set_2]\n",
    "# )"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2689f82fbeacfdf1986d1920a0c288142f5de68ce628bbd1eab730fa0ce156c8"
  },
  "kernelspec": {
   "display_name": "Python 3.8.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
